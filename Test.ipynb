{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1LGqXoKK5x7OUJCT8Kc_ryi_GU2Z-vSV_","authorship_tag":"ABX9TyPx7Yp1UH0lPjcvxyjf+gZt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5RK7nQm-JtIl"},"source":["## **Load Libraries**"]},{"cell_type":"code","metadata":{"id":"Mq2Nst9_3CNl"},"source":["import os\n","import tqdm\n","import shutil\n","import pickle\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from keras.models import load_model\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1_7eSPWlD-P"},"source":["import matplotlib\n","matplotlib.use('agg') # Use Agg Backend For Matplotlib"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IqeRNU8t6Rxx"},"source":["## **Mount Drive**"]},{"cell_type":"code","metadata":{"id":"yXJhOymb6Vyr"},"source":["from google.colab import drive\n","drive.mount('/content/drive') # Mounts Drive In Content Directory (Under Files Section)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"64ZawZGh6Xc2"},"source":["Path = r'/content/drive/MyDrive/ECG ML'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IlH3zRSc6cFi"},"source":["## **Load Dataset**"]},{"cell_type":"code","metadata":{"id":"dV5rTXfeF0kY"},"source":["# Load Data List From Pickle Format\n","pickle_in = open(os.path.join(Path, 'Dataset', 'Training_Data.pickle'), 'rb')\n","Training_Data = pickle.load(pickle_in)\n","pickle_in.close()\n"," \n","pickle_in = open(os.path.join(Path, 'Dataset', 'Validation_Data.pickle'), 'rb')\n","Validation_Data = pickle.load(pickle_in)\n","pickle_in.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWQlTIiJ9Qf3"},"source":["# Load Test Data From TXT or CSV Files\n","Test_Data = []\n","\n","Dict = {'nan': -1, 'Normal': 0, 'LBBB': 1, 'RBBB': 2, 'PVC': 3}\n","main_df = pd.read_excel(os.path.join(Path, 'Test', 'Reference.xlsx'), index_col = 'Recording').sort_index()\n","\n","for Folder_Name in main_df.index:\n","  Label = str(main_df.loc[Folder_Name, 'Label'])\n","  Files = os.listdir(os.path.join(Path, 'Test', Folder_Name))\n","  \n","  if len(Files) == 12:\n","    for index, File_Name in enumerate(sorted(Files)):\n","      Data = np.genfromtxt(os.path.join(Path, 'Test', Folder_Name, File_Name), dtype = np.float64)\n","\n","      # Drop Excess Data Or Fill Up Missing Data\n","      Length = len(Data)\n","      if Length > 2800:\n","        Data = Data[:2800]\n","      elif Length < 2800:\n","        for _ in range(2800 - Length):\n","          Data = np.append(Data, Data[-1])\n","\n","      if index == 0:\n","        File = Data \n","      else:  \n","        File = np.column_stack((File, Data))\n","    \n","    Test_Data.append([File, Dict[Label]])\n","\n","  elif len(Files) == 1:\n","    Data = np.genfromtxt(os.path.join(Path, 'Test', Folder_Name, Files[0]), dtype = np.float64, delimiter = ',', skip_header = 1)\n","\n","    # Drop Excess Data Or Fill Up Missing Data\n","    Length = len(Data)\n","    if Length > 2800:\n","      Data = Data[:2800]\n","    elif Length < 2800:\n","      for _ in range(2800 - Length):\n","        Data = np.vstack((Data, Data[-1]))\n","\n","    Test_Data.append([Data, Dict[Label]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fSLfq-RqEcKV"},"source":["## **Initialize TPU**"]},{"cell_type":"code","metadata":{"id":"oD-MnPR3Ed05"},"source":["# Standard Syntax Code To Intialize TPU\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","strategy = tf.distribute.TPUStrategy(resolver)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fmI2LaYszaj4"},"source":["## **Load Best Accuracy Model**"]},{"cell_type":"code","metadata":{"id":"ZG7dhP4xzeYa"},"source":["# Loads Model\n","model = load_model(os.path.join(Path, 'Model', 'best_val_acc.h5'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjdQSAztHNvg"},"source":["## **Accuracy on Best Accuracy Model**"]},{"cell_type":"code","metadata":{"id":"UyREYXubRPdd"},"source":["# Separate Target\n","x, y = np.array([Sample[0] for Sample in Test_Data], dtype = np.float64), np.array([Sample[1] for Sample in Test_Data], dtype = np.int64)\n","\n","# Check If All Labels Are Present, If So Evaluate Model\n","if -1 not in y:\n","  y = to_categorical(y)\n","\n","  loss, acc = model.evaluate(x, y)\n","  print('Loss on Test Data : ', loss)\n","  print('Accuracy on Test Data :', '{:.4%}'.format(acc))\n","else:\n","  print('True labels absent')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rfZJT9LhRDeD"},"source":["## **Load Best Loss Model**"]},{"cell_type":"code","metadata":{"id":"kn9udY49RFmc"},"source":["# Loads Model\n","model = load_model(os.path.join(Path, 'Model', 'best_val_loss.h5'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L4OqqNDKRssY"},"source":["## **Accuracy on Best Loss Model**"]},{"cell_type":"code","metadata":{"id":"XJJGMY22RssZ"},"source":["x, y = np.array([Sample[0] for Sample in Test_Data], dtype = np.float64), np.array([Sample[1] for Sample in Test_Data], dtype = np.int64)\n","\n","# Check If All Labels Are Present, If So Evaluate Model\n","if -1 not in y:\n","  y = to_categorical(y)\n","\n","  loss, acc = model.evaluate(x, y)\n","  print('Loss on Test Data : ', loss)\n","  print('Accuracy on Test Data :', '{:.4%}'.format(acc))\n","else:\n","  print('True labels absent')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXJ-UR3VWFjJ"},"source":["## **Figures**"]},{"cell_type":"code","metadata":{"id":"-Xh6vmsxWCQW"},"source":["plt.style.use('seaborn') # Style To Use For Matplotlib Plots\n"," \n","Time = [i / 500 for i in range(2800)]\n","Dict = {-1: 'nan', 0: 'Normal', 1: 'LBBB', 2: 'RBBB', 3: 'PVC'}\n","Labels = ['DI','DII','DIII','AVR','AVL','AVF','V1','V2','V3','V4','V5','V6']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPbPl_Kp2y1i"},"source":["if os.path.isdir(os.path.join(Path, 'Test Figures (Lead II)')): # Checks If Directory Exist\n","    shutil.rmtree(os.path.join(Path, 'Test Figures (Lead II)')) # Removes Directory\n","os.mkdir(os.path.join(Path, 'Test Figures (Lead II)')) # Creates Directory\n","\n","Count = 0    \n","for Sample, Label in tqdm.tqdm(Test_Data, unit_scale = True, miniters = 1, desc = 'Plotting Test Data (Lead II) '): # Progress Bar\n","    df = pd.DataFrame(Sample)\n","\n","    # Plot And Save\n","    fig, ax = plt.subplots(1)\n","    fig.set_size_inches(37.33, 11.5)\n","\n","    ax.plot(Time, df.iloc[:, 1], 'b', label = Labels[1])\n","    ax.legend(loc = 'upper right', prop = {'size': 18})\n","    ax.set_xlabel('Time', fontsize = 18)\n","    ax.set_ylabel('mV', fontsize = 18)  \n","    ax.yaxis.label.set_color('black')\n","    ax.xaxis.label.set_color('black')\n","    ax.tick_params(axis = 'both', colors = 'black', labelsize = 16)\n","\n","    fig.tight_layout()\n","    fig.suptitle(Dict[Label], fontsize = 22)\n","    fig.subplots_adjust(top = 0.96, right = 0.978)\n","    fig.savefig(os.path.join(Path, 'Test Figures (Lead II)', f'Figure {Count}.png'), dpi = 300)\n","    plt.close(fig)\n"," \n","    Count += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqWSI938WWX5"},"source":["if os.path.isdir(os.path.join(Path, 'Test Figures')): # Checks If Directory Exist\n","  shutil.rmtree(os.path.join(Path, 'Test Figures')) # Removes Directory\n","os.mkdir(os.path.join(Path, 'Test Figures')) # Creates Directory\n","\n","Count = 0\n","for Sample, Label in tqdm.tqdm(Test_Data, unit_scale = True, miniters = 1, desc = 'Plotting Test Data '):\n","  df = pd.DataFrame(Sample)\n","  \n","  # Plot And Save\n","  fig, ax = plt.subplots(6, 2, sharex = True)\n","  fig.set_size_inches(37.33, 21)\n","  for i in range(2):\n","    for j in range(6):\n","      ax[j][i].plot(Time, df.iloc[:, i * 6 + j], 'b', label = Labels[i * 6 + j])\n","      ax[j][i].legend(loc = 'upper right', prop = {\"size\": 14})\n","      ax[j][i].set_ylabel('mV', fontsize = 12)  \n","      ax[j][i].yaxis.label.set_color('black')\n","      ax[j][i].tick_params(axis = 'both', colors = 'black')\n","    ax[j][i].set_xlabel('Time', fontsize = 12)\n","    ax[j][i].xaxis.label.set_color('black')\n","  fig.tight_layout()\n","  fig.suptitle(Dict[Label], fontsize = 18)\n","  fig.subplots_adjust(top = 0.96, right = 0.978)\n","  fig.savefig(os.path.join(Path, 'Test Figures', f'{main_df.index[Count]}.png'), dpi = 300)\n","  plt.close(fig)\n","\n","  Count += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B4JRF1sSIi2c"},"source":["## **Predictions**"]},{"cell_type":"code","metadata":{"id":"XWg7ZiQIXJoE"},"source":["Dict = {-1: 'nan', 0: 'Normal', 1: 'LBBB', 2: 'RBBB', 3: 'PVC'}\n","\n","# Separate Target Variable\n","x, y = np.array([Sample[0] for Sample in Test_Data], dtype = np.float64), np.array([Sample[1] for Sample in Test_Data], dtype = np.int64)\n","\n","# Take Predictions\n","y_true = [Dict[Label] for Label in y]\n","y_pred = [Dict[Label] for Label in np.argmax(model.predict(x), axis = 1)]\n","\n","# Push Results To CSV File\n","Results = pd.DataFrame(list(zip(main_df.index, y_true, y_pred)), columns = ['Name', 'Actual', 'Prediction'])\n","Results.to_csv(os.path.join(Path, 'Test Results.csv'), index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9P9m8qc6VBam"},"source":["Results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UxLvsck1F269"},"source":["## **Single Training Data File**"]},{"cell_type":"code","metadata":{"id":"cWpPziceF6nZ"},"source":["Dict = {0: 'Normal', 1: 'LBBB', 2: 'RBBB', 3: 'PVC'}\n","\n","Class = random.randint(0, 3) # [0, 3] Included, Class to Use\n","Sample = random.randint(0, len(Training_Data[Class]) - 1) # [0, len(Training_Data[Class]) - 1] Included, Sample to Use\n","\n","# Take Prediction\n","print('Prediction:', Dict[np.argmax(model.predict(np.array([Training_Data[Class][Sample]])))])\n","print('Actual:', Dict[Class])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OOCDpNLhvhQ-"},"source":["## **Single Test Data File**"]},{"cell_type":"code","metadata":{"id":"68DGlAXvvhRD"},"source":["Folder_Name = 'A0001' # Enter Folder Name Here\n","True_Label = 'RBBB' # Enter True Label Here ('nan' If Not Known)\n","\n","Dict = {0: 'Normal', 1: 'LBBB', 2: 'RBBB', 3: 'PVC'}\n","Files = os.listdir(os.path.join(Path, 'Test', Folder_Name))\n","\n","if len(Files) == 12:\n","  for index, File_Name in enumerate(sorted(Files)):\n","    Data = np.genfromtxt(os.path.join(Path, 'Test', Folder_Name, File_Name), dtype = np.float64)\n","\n","    # Drop Excess Data Or Fill Up Missing Data\n","    Length = len(Data)\n","    if Length > 2800:\n","      Data = Data[:2800]\n","    elif Length < 2800:\n","      for _ in range(2800 - Length):\n","        Data = np.append(Data, Data[-1])\n","\n","    if index == 0:\n","      File = Data \n","    else:  \n","      File = np.column_stack((File, Data))\n","\n","elif len(Files) == 1:\n","  Data = np.genfromtxt(os.path.join(Path, 'Test', Folder_Name, Files[0]), dtype = np.float64, delimiter = ',', skip_header = 1)\n","\n","  # Drop Excess Data Or Fill Up Missing Data\n","  Length = len(Data)\n","  if Length >= 2800:\n","    Data = Data[:2800]\n","  elif Length < 2800:\n","    for _ in range(2800 - Length):\n","      Data = np.vstack((Data, Data[-1]))\n","  \n","  File = Data.copy()\n","\n","# Take Prediction\n","print('Prediction:', Dict[np.argmax(model.predict(np.array([File])))])\n","print('Actual:', True_Label)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YkPTG8p0lAe7"},"source":["## **Lead DII Stacked Plots**"]},{"cell_type":"code","metadata":{"id":"PVpZjhsbnXRh"},"source":["plt.style.use('seaborn') # Style To Use For Matplotlib Plots\n"," \n","Time = [i / 500 for i in range(2800)]\n","Dict = {-1: 'nan', 0: 'Normal', 1: 'LBBB', 2: 'RBBB', 3: 'PVC'}\n","Labels = ['DI','DII','DIII','AVR','AVL','AVF','V1','V2','V3','V4','V5','V6']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgcFI2HulFu4"},"source":["if os.path.isdir(os.path.join(Path, 'Stacked Lead II Figures')): # Checks If Directory Exist\n","    shutil.rmtree(os.path.join(Path, 'Stacked Lead II Figures')) # Removes Directory\n","os.mkdir(os.path.join(Path, 'Stacked Lead II Figures')) # Creates Directory\n","\n","Count = 0\n","for Test_File, Label in Test_Data:\n","  Sample = random.randint(0, len(Training_Data[Label]) - 1)\n","  Train_File = Training_Data[Label][Sample]\n","\n","  test_df = pd.DataFrame(Test_File)\n","  train_df = pd.DataFrame(Train_File)\n","\n","  # Plot And Save\n","  fig, ax = plt.subplots(2, sharex = True)\n","  fig.set_size_inches(37.33, 21)\n","\n","  ax[0].plot(Time, train_df.iloc[:, 1], 'b', label = 'Train Lead II')\n","  ax[1].plot(Time, test_df.iloc[:, 1], 'b', label = 'Test Lead II')\n","\n","  for i in range(2):\n","    ax[i].legend(loc = 'upper right', prop = {'size': 18})\n","    ax[i].set_ylabel('mV', fontsize = 18)  \n","    ax[i].yaxis.label.set_color('black')\n","    ax[i].tick_params(axis = 'both', colors = 'black', labelsize = 16)\n","  ax[i].set_xlabel('Time', fontsize = 18)\n","  ax[i].xaxis.label.set_color('black')\n","\n","  fig.tight_layout()\n","  fig.suptitle(Dict[Label], fontsize = 22)\n","  fig.subplots_adjust(top = 0.96, right = 0.978)\n","  fig.savefig(os.path.join(Path, 'Stacked Lead II Figures', f'Figure {Count}.png'), dpi = 300)\n","  plt.close(fig)\n","\n","  Count += 1"],"execution_count":null,"outputs":[]}]}